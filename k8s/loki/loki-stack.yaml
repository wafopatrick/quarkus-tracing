apiVersion: v1
kind: Namespace
metadata:
  name: logging
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: observability
  labels:
    grafana_datasource: "1"
    app.kubernetes.io/name: grafana
    app.kubernetes.io/part-of: grafana
    app.kubernetes.io/component: datasources
    app.kubernetes.io/managed-by: manual
    app.kubernetes.io/version: v1
  annotations:
    k8s-sidecar-target-directory: "/tmp/datasources"
    k8s-sidecar-label: grafana_datasource
    k8s-sidecar-label-value: "1"
    k8s-sidecar-folder: "/etc/grafana/provisioning/datasources"
    force-update: "true"
    reload: "true"
data:
  loki.yaml: |
    apiVersion: 1
    datasources:
      - name: Loki
        type: loki
        access: proxy
        url: http://loki.logging:3100
        isDefault: true
      - name: Jaeger
        type: jaeger
        access: proxy
        url: http://jaeger-query.observability:16686
---
# Loki single binary, Promtail and Grafana via Helm would be typical; here we include minimal manifests for local env
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki
  namespace: logging
  labels:
    app: loki
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
        - name: loki
          image: grafana/loki:2.9.6
          args: ["-config.file=/etc/loki/local-config.yaml"]
          ports:
            - containerPort: 3100
          volumeMounts:
            - name: config
              mountPath: /etc/loki/local-config.yaml
              subPath: local-config.yaml
      volumes:
        - name: config
          configMap:
            name: loki-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
  labels:
    app: loki
data:
  local-config.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
    common:
      instance_addr: 127.0.0.1
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory
    schema_config:
      configs:
      - from: 2020-10-24
        store: boltdb-shipper
        object_store: filesystem
        schema: v13
        index:
          prefix: index_
          period: 24h
    ruler:
      alertmanager_url: http://localhost:9093
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
spec:
  selector:
    app: loki
  ports:
    - port: 3100
      targetPort: 3100
      name: http
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
  labels:
    app: promtail
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
        - name: promtail
          image: grafana/promtail:2.9.6
          args: ["-config.file=/etc/promtail/config.yaml"]
          volumeMounts:
            - name: config
              mountPath: /etc/promtail/config.yaml
              subPath: config.yaml
            - name: varlog
              mountPath: /var/log
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
      volumes:
        - name: config
          configMap:
            name: promtail-config
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
  labels:
    app: promtail
data:
  config.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0
    positions:
      filename: /tmp/positions.yaml
    clients:
      - url: http://loki.logging:3100/loki/api/v1/push
    scrape_configs:
      - job_name: kubernetes-pods
        pipeline_stages:
          - json:
              expressions:
                traceId: traceId
                spanId: spanId
                service: service
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: ["__meta_kubernetes_pod_node_name"]
            target_label: "__host__"
          - action: replace
            source_labels: ["__meta_kubernetes_pod_uid"]
            target_label: "pod_uid"
          - action: replace
            source_labels: ["__meta_kubernetes_pod_name"]
            target_label: "pod"
          - action: replace
            source_labels: ["__meta_kubernetes_namespace"]
            target_label: "namespace"
          - action: replace
            source_labels: ["__meta_kubernetes_pod_container_name"]
            target_label: "container"
          - action: replace
            replacement: "/var/log/pods/*$1/*.log"
            separator: /
            regex: (.*)
            source_labels: ["pod_uid"]
            target_label: "__path__"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: logging
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail-clusterrole
rules:
  - apiGroups: [""]
    resources: ["pods", "nodes"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail-clusterrolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail-clusterrole
subjects:
  - kind: ServiceAccount
    name: promtail
    namespace: logging
